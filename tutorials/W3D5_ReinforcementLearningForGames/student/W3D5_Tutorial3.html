
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 3: Policy-based Player — Neuromatch Academy: Deep Learning</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-dl-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D5_Tutorial4.html" rel="next" title="Bonus Tutorial: Planning with Monte Carlo"/>
<link href="W3D5_Tutorial2.html" rel="prev" title="Tutorial 2: Value-Based Player"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/DeepLearning.html">
   Prerequisites and preparatory materials for NMA Deep Learning
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Basics Module
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">
     Bonus Lecture: Yoshua Bengio
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Fine Tuning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Optimization/chapter_title.html">
   Optimization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Optimization/student/W1D5_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_Regularization/chapter_title.html">
   Regularization (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/FineTuning.html">
   Deep Learning: The Basics and Fine Tuning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/chapter_title.html">
   Convnets And Dl Thinking (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">
     Tutorial 2: Deep Learning Thinking 1: Cost Functions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">
     Bonus Lecture: Kyunghyun Cho
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial2.html">
     (Bonus) Tutorial 2: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_GenerativeModels/chapter_title.html">
   Generative Models (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial2.html">
     Tutorial 2: Introduction to GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial4.html">
     (Bonus) Tutorial 4: Deploying Neural Networks on the Web
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_BonusLecture.html">
     Bonus Lecture: Geoffrey Hinton
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
   Time Series And Natural Language Processing (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial1.html">
     Tutorial 1: Introduction to processing time series
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.html">
     Tutorial 2: Time series for Language
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial3.html">
     (Bonus) Tutorial 3: Multilingual Embeddings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/student/W3D1_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_DlThinking2/chapter_title.html">
   Dl Thinking2 (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_DlThinking2/student/W3D2_Tutorial1.html">
     Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/NaturalLanguageProcessing.html">
   Deep Learning: Convnets and NLP
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">
     Bonus Lecture: Melanie Mitchell
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial5.html">
     (Bonus) Tutorial 5: Function approximation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">
     Bonus Lecture: Chealsea Finn
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Reinforcement Learning For Games (W3D5)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W3D5_Tutorial1.html">
     Tutorial 1: Game Set-Up and Random Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D5_Tutorial2.html">
     Tutorial 2: Value-Based Player
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 3: Policy-based Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D5_Tutorial4.html">
     Bonus Tutorial: Planning with Monte Carlo
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D5_BonusLecture.html">
     Bonus Lecture: Amita Kapoor
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/ReinforcementLearning.html">
   Deep Learning: Reinforcement Learning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial3.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial3.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: Policy-based Player
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-the-modules">
     Download the modules
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions-from-previous-tutorials">
     Helper functions from previous tutorials
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-train-a-policy-network-from-expert-game-data">
   Section 1: Train a policy network from expert game data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-train-a-policy-network">
     Video 1: Train a policy network
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-implement-policynetwork">
     Coding Exercise 1: Implement
     <code class="docutils literal notranslate">
<span class="pre">
       PolicyNetwork
      </span>
</code>
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-the-policy-network">
       Train the policy network
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-use-a-trained-policy-network-to-play-games">
   Section 2: Use a trained policy network to play games
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-play-games-using-a-policy-network">
     Video 2: Play games using a policy network
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-implement-the-policybasedplayer">
     Coding Exercise 2: Implement the
     <code class="docutils literal notranslate">
<span class="pre">
       PolicyBasedPlayer
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-player-comparisons">
   Section 3: Player comparisons
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-a-sampling-based-policy-based-player-versus-a-random-player">
     Comparing a sampling-based policy based player versus a random player
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#compare-greedy-policy-based-player-versus-value-based-player">
     Compare greedy policy based player versus value based player
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#compare-greedy-policy-based-player-versus-sampling-based-policy-player">
     Compare greedy policy based player versus sampling-based policy player
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-ethical-aspects">
   Section 4: Ethical aspects
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-unstoppable-opponents">
     Video 3: Unstoppable opponents
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 3: Policy-based Player</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: Policy-based Player
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-the-modules">
     Download the modules
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions-from-previous-tutorials">
     Helper functions from previous tutorials
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-train-a-policy-network-from-expert-game-data">
   Section 1: Train a policy network from expert game data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-train-a-policy-network">
     Video 1: Train a policy network
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-implement-policynetwork">
     Coding Exercise 1: Implement
     <code class="docutils literal notranslate">
<span class="pre">
       PolicyNetwork
      </span>
</code>
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-the-policy-network">
       Train the policy network
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-use-a-trained-policy-network-to-play-games">
   Section 2: Use a trained policy network to play games
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-play-games-using-a-policy-network">
     Video 2: Play games using a policy network
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-implement-the-policybasedplayer">
     Coding Exercise 2: Implement the
     <code class="docutils literal notranslate">
<span class="pre">
       PolicyBasedPlayer
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-player-comparisons">
   Section 3: Player comparisons
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-a-sampling-based-policy-based-player-versus-a-random-player">
     Comparing a sampling-based policy based player versus a random player
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#compare-greedy-policy-based-player-versus-value-based-player">
     Compare greedy policy based player versus value based player
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#compare-greedy-policy-based-player-versus-sampling-based-policy-player">
     Compare greedy policy based player versus sampling-based policy player
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-ethical-aspects">
   Section 4: Ethical aspects
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-unstoppable-opponents">
     Video 3: Unstoppable opponents
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial3.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial3.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-3-policy-based-player">
<h1>Tutorial 3: Policy-based Player<a class="headerlink" href="#tutorial-3-policy-based-player" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 5: Reinforcement Learning for Games</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Mandana Samiei, Raymond Chua, Tim Lilicrap, Blake Richards</p>
<p><strong>Content reviewers:</strong> Arush Tagade, Lily Cheng, Melvin Selim Atay, Kelson Shilling-Scrivo</p>
<p><strong>Content editors:</strong> Melvin Selim Atay, Spiros Chavlis, Gunnar Blohm</p>
<p><strong>Production editors:</strong> Namrata Bafna, Gagana B, Spiros Chavlis</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, you will learn how to implement a game loop and improve the performance of a random player.</p>
<p>The specific objectives for this tutorial:</p>
<ul class="simple">
<li><p>Understand the format of two-players games</p></li>
<li><p>Learn about value network and policy network</p></li>
</ul>
<p>In the Bonus sections you will learn about Monte Carlo Tree Search (MCTS) and compare its performance to policy-based and value-based players.</p>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/r6tup/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
<p>These are the slides for the videos in the tutorial. If you want to locally download the slides, click <a class="reference external" href="https://osf.io/r6tup/download">here</a>.</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip install coloredlogs --quiet

<span class="o">!</span>pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet
<span class="kn">from</span> <span class="nn">evaltools.airtable</span> <span class="kn">import</span> <span class="n">AirtableForm</span>

<span class="c1"># generate airtable form</span>
<span class="n">atform</span> <span class="o">=</span> <span class="n">AirtableForm</span><span class="p">(</span><span class="s1">'appn7VdPRseSoMXEG'</span><span class="p">,</span><span class="s1">'W3D5_T3'</span><span class="p">,</span><span class="s1">'https://portal.neuromatchacademy.org/api/redirect/to/95651a47-083f-406e-a6cd-8af24670c5bc'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">coloredlogs</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">pickle</span> <span class="kn">import</span> <span class="n">Unpickler</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="n">coloredlogs</span><span class="o">.</span><span class="n">install</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="s1">'INFO'</span><span class="p">)</span>  <span class="c1"># Change this to DEBUG to see more info.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># For DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Function that controls randomness. NumPy and random modules must be imported.</span>

<span class="sd">  Args:</span>
<span class="sd">    seed : Integer</span>
<span class="sd">      A non-negative integer that defines the random state. Default is `None`.</span>
<span class="sd">    seed_torch : Boolean</span>
<span class="sd">      If `True` sets the random seed for pytorch tensors, so pytorch module</span>
<span class="sd">      must be imported. Default is `True`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  DataLoader will reseed workers following randomness in</span>
<span class="sd">  multi-process data loading algorithm.</span>

<span class="sd">  Args:</span>
<span class="sd">    worker_id: integer</span>
<span class="sd">      ID of subprocess to seed. 0 means that</span>
<span class="sd">      the data will be loaded in the main process</span>
<span class="sd">      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># Inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Set the device. CUDA if available, CPU otherwise</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="download-the-modules">
<h2>Download the modules<a class="headerlink" href="#download-the-modules" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download the modules</span>

<span class="c1"># @markdown Run this cell!</span>

<span class="c1"># @markdown Download from OSF. The original repo is https://github.com/raymondchua/nma_rl_games.git</span>

<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">io</span><span class="o">,</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">shutil</span><span class="o">,</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlopen</span>

<span class="c1"># download from github repo directly</span>
<span class="c1">#!git clone git://github.com/raymondchua/nma_rl_games.git --quiet</span>
<span class="n">REPO_PATH</span> <span class="o">=</span> <span class="s1">'nma_rl_games'</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">REPO_PATH</span><span class="p">):</span>
  <span class="n">download_string</span> <span class="o">=</span> <span class="s2">"Redownloading"</span>
  <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">REPO_PATH</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">download_string</span> <span class="o">=</span> <span class="s2">"Downloading"</span>

<span class="n">zipurl</span> <span class="o">=</span> <span class="s1">'https://osf.io/kf4p9/download'</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">download_string</span><span class="si">}</span><span class="s2"> and unzipping the file... Please wait."</span><span class="p">)</span>
<span class="k">with</span> <span class="n">urlopen</span><span class="p">(</span><span class="n">zipurl</span><span class="p">)</span> <span class="k">as</span> <span class="n">zipresp</span><span class="p">:</span>
  <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">zipresp</span><span class="o">.</span><span class="n">read</span><span class="p">()))</span> <span class="k">as</span> <span class="n">zfile</span><span class="p">:</span>
    <span class="n">zfile</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Download completed."</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Add the </span><span class="si">{</span><span class="n">REPO_PATH</span><span class="si">}</span><span class="s2"> in the path and import the modules."</span><span class="p">)</span>
<span class="c1"># add the repo in the path</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'nma_rl_games/alpha-zero'</span><span class="p">)</span>

<span class="c1"># @markdown Import modules designed for use in this notebook</span>
<span class="kn">import</span> <span class="nn">Arena</span>

<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">Game</span> <span class="kn">import</span> <span class="n">Game</span>
<span class="kn">from</span> <span class="nn">NeuralNet</span> <span class="kn">import</span> <span class="n">NeuralNet</span>

<span class="kn">from</span> <span class="nn">othello.OthelloLogic</span> <span class="kn">import</span> <span class="n">Board</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Redownloading and unzipping the file... Please wait.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Download completed.
Add the nma_rl_games in the path and import the modules.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions-from-previous-tutorials">
<h2>Helper functions from previous tutorials<a class="headerlink" href="#helper-functions-from-previous-tutorials" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions from previous tutorials</span>
<span class="k">class</span> <span class="nc">OthelloGame</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Instantiate Othello Game</span>
<span class="sd">  """</span>
  <span class="n">square_content</span> <span class="o">=</span> <span class="p">{</span>
      <span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">"X"</span><span class="p">,</span>
      <span class="o">+</span><span class="mi">0</span><span class="p">:</span> <span class="s2">"-"</span><span class="p">,</span>
      <span class="o">+</span><span class="mi">1</span><span class="p">:</span> <span class="s2">"O"</span>
      <span class="p">}</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">getSquarePiece</span><span class="p">(</span><span class="n">piece</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">OthelloGame</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">piece</span><span class="p">]</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>

  <span class="k">def</span> <span class="nf">getInitBoard</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Return initial board (numpy board)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">pieces</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getBoardSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># (a,b) tuple</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getActionSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Return number of actions, n is the board size and +1 is for no-op action</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span>

  <span class="k">def</span> <span class="nf">getCanonicalForm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="c1"># Return state if player==1, else return -state if player==-1</span>
    <span class="k">return</span> <span class="n">player</span><span class="o">*</span><span class="n">board</span>

  <span class="k">def</span> <span class="nf">stringRepresentation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">board</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">stringRepresentationReadable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="n">board_s</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">square</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">board</span> <span class="k">for</span> <span class="n">square</span> <span class="ow">in</span> <span class="n">row</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">board_s</span>

  <span class="k">def</span> <span class="nf">getScore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">b</span><span class="o">.</span><span class="n">countDiff</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">display</span><span class="p">(</span><span class="n">board</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">"|"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>    <span class="c1"># Print the row</span>
      <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">piece</span> <span class="o">=</span> <span class="n">board</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span>    <span class="c1"># Get the piece to print</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">piece</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"|"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">displayValidMoves</span><span class="p">(</span><span class="n">moves</span><span class="p">):</span>
      <span class="c1"># Display possible moves</span>
      <span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">moves</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">board</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"  "</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"possible moves"</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"   "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">"|"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>    <span class="c1"># Print the row</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
          <span class="n">piece</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span>    <span class="c1"># Get the piece to print</span>
          <span class="nb">print</span><span class="p">(</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">piece</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"|"</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getNextState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Helper function to make valid move</span>
<span class="sd">    If player takes action on board, return next (board,player)</span>
<span class="sd">    and action must be a valid move</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      player: Integer</span>
<span class="sd">        ID of current player</span>
<span class="sd">      action: np.ndarray</span>
<span class="sd">        Space of actions</span>

<span class="sd">    Returns:</span>
<span class="sd">      (board,player) tuple signifying next state</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="o">-</span><span class="n">player</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="n">move</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">action</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">),</span> <span class="n">action</span><span class="o">%</span><span class="k">self</span>.n)
    <span class="n">b</span><span class="o">.</span><span class="n">execute_move</span><span class="p">(</span><span class="n">move</span><span class="p">,</span> <span class="n">player</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">pieces</span><span class="p">,</span> <span class="o">-</span><span class="n">player</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getValidMoves</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Helper function to make valid move</span>
<span class="sd">    If player takes action on board, return next (board,player)</span>
<span class="sd">    and action must be a valid move</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      player: Integer</span>
<span class="sd">        ID of current player</span>
<span class="sd">      action: np.ndarray</span>
<span class="sd">        Space of action</span>

<span class="sd">    Returns:</span>
<span class="sd">      valids: np.ndarray</span>
<span class="sd">        Returns a fixed size binary vector</span>
<span class="sd">    """</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="n">legalMoves</span> <span class="o">=</span>  <span class="n">b</span><span class="o">.</span><span class="n">get_legal_moves</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">legalMoves</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
      <span class="n">valids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valids</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">legalMoves</span><span class="p">:</span>
      <span class="n">valids</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valids</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getGameEnded</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Helper function to signify if game has ended</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      player: Integer</span>
<span class="sd">        ID of current player</span>

<span class="sd">    Returns:</span>
<span class="sd">      0 if not ended, 1 if player 1 won, -1 if player 1 lost</span>
<span class="sd">    """</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">has_legal_moves</span><span class="p">(</span><span class="n">player</span><span class="p">):</span>
      <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">has_legal_moves</span><span class="p">(</span><span class="o">-</span><span class="n">player</span><span class="p">):</span>
      <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">countDiff</span><span class="p">(</span><span class="n">player</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">def</span> <span class="nf">getSymmetries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Get mirror/rotational configurations of board</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      pi: np.ndarray</span>
<span class="sd">        Dimension of board</span>

<span class="sd">    Returns:</span>
<span class="sd">      l: list</span>
<span class="sd">        90 degree of board, 90 degree of pi_board</span>
<span class="sd">    """</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 1 for pass</span>
    <span class="n">pi_board</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pi</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
        <span class="n">newB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">newPi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">pi_board</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">j</span><span class="p">:</span>
          <span class="n">newB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">newB</span><span class="p">)</span>
          <span class="n">newPi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">newPi</span><span class="p">)</span>
        <span class="n">l</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">newB</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">newPi</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">pi</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])]</span>
    <span class="k">return</span> <span class="n">l</span>

<span class="k">class</span> <span class="nc">RandomPlayer</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Simulates Random Player</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Simulates game play</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      a: int</span>
<span class="sd">        Randomly chosen move</span>
<span class="sd">    """</span>

    <span class="c1"># Compute the valid moves using getValidMoves()</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute the probability of each move being played (random player means this should</span>
    <span class="c1"># be uniform for valid moves, 0 for others)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">valids</span><span class="o">/</span><span class="n">valids</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Pick an action based on the probabilities (hint: np.choice is useful)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="n">prob</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span>

<span class="k">class</span> <span class="nc">OthelloNNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Instantiate Othello Neural Net with following configuration</span>
<span class="sd">  nn.Conv2d(1, args.num_channels, 3, stride=1, padding=1) # Convolutional Layer 1</span>
<span class="sd">  nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1, padding=1) # Convolutional Layer 2</span>
<span class="sd">  nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1) # Convolutional Layer 3</span>
<span class="sd">  nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1) # Convolutional Layer 4</span>
<span class="sd">  nn.BatchNorm2d(args.num_channels) X 4</span>
<span class="sd">  nn.Linear(args.num_channels * (self.board_x - 4) * (self.board_y - 4), 1024) # Fully-connected Layer 1</span>
<span class="sd">  nn.Linear(1024, 512) # Fully-connected Layer 2</span>
<span class="sd">  nn.Linear(512, self.action_size) # Fully-connected Layer 3</span>
<span class="sd">  nn.Linear(512, 1) # Fully-connected Layer 4</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Initialise game parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      args: dictionary</span>
<span class="sd">        Instantiates number of iterations and episodes, controls temperature threshold, queue length,</span>
<span class="sd">        arena, checkpointing, and neural network parameters:</span>
<span class="sd">        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,</span>
<span class="sd">        num_channels: 512</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getBoardSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">OthelloNNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bn4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_x</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">-</span> <span class="mi">4</span><span class="p">),</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc_bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc_bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Controls forward pass of OthelloNNet</span>

<span class="sd">    Args:</span>
<span class="sd">      s: np.ndarray</span>
<span class="sd">        Array of size (batch_size x board_x x board_y)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Probability distribution over actions at the current state and the value of the current state.</span>
<span class="sd">    """</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span><span class="p">)</span>                <span class="c1"># batch_size x 1 x board_x x board_y</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x board_x x board_y</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x board_x x board_y</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x (board_x-2) x (board_y-2)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn4</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x (board_x-4) x (board_y-4)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_x</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">-</span> <span class="mi">4</span><span class="p">))</span> <span class="c1"># reshaping of</span>

    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">s</span><span class="p">))),</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>  <span class="c1"># batch_size x 1024</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">s</span><span class="p">))),</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>  <span class="c1"># batch_size x 512</span>

    <span class="n">pi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># batch_size x action_size</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>   <span class="c1"># batch_size x 1</span>

    <span class="c1"># Returns probability distribution over actions at the current state and the value of the current state.</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ValueBasedPlayer</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Simulate Value Based Player</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">vnet</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Initialise value based player parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      vnet: Value Network instance</span>
<span class="sd">        Instance of the Value Network class above;</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vnet</span> <span class="o">=</span> <span class="n">vnet</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Simulate game play</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      candidates: List</span>
<span class="sd">        Collection of tuples describing action and values of future predicted states</span>
<span class="sd">    """</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">max_num_actions</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">va</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">valids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">va_list</span> <span class="o">=</span> <span class="n">va</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">va_list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">va_list</span><span class="p">:</span>
      <span class="c1"># Return next board state using getNextState() function</span>
      <span class="n">nextBoard</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getNextState</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
      <span class="c1"># Predict the value of next state using value network</span>
      <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">nextBoard</span><span class="p">)</span>
      <span class="c1"># Add the value and the action as a tuple to the candidate lists, note that you might need to change the sign of the value based on the player</span>
      <span class="n">candidates</span> <span class="o">+=</span> <span class="p">[(</span><span class="o">-</span><span class="n">value</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span>

      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">==</span> <span class="n">max_num_actions</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Sort by the values</span>
    <span class="n">candidates</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="c1"># Return action associated with highest value</span>
    <span class="k">return</span> <span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">ValueNetwork</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Initiates the Value Network</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Initialise network parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">OthelloNNet</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getBoardSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">games</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Function to train value network</span>

<span class="sd">    Args:</span>
<span class="sd">      games: list</span>
<span class="sd">        List of examples with each example is of form (board, pi, v)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">examples</span> <span class="ow">in</span> <span class="n">games</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'EPOCH ::: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">v_losses</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># To store the losses per epoch</span>
        <span class="n">batch_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># len(examples)=200, batch-size=64, batch_count=3</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch_count</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Training Value Network'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
          <span class="n">sample_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># Read the ground truth information from MCTS simulation using the loaded examples</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">pis</span><span class="p">,</span> <span class="n">vs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample_ids</span><span class="p">]))</span>  <span class="c1"># Length of boards, pis, vis = 64</span>
          <span class="n">boards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
          <span class="n">target_vs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>

          <span class="c1"># Predict</span>
          <span class="c1"># To run on GPU if available</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">target_vs</span> <span class="o">=</span> <span class="n">boards</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target_vs</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

          <span class="c1"># Compute output</span>
          <span class="n">_</span><span class="p">,</span> <span class="n">out_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span>
          <span class="n">l_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_v</span><span class="p">(</span><span class="n">target_vs</span><span class="p">,</span> <span class="n">out_v</span><span class="p">)</span>  <span class="c1"># Total loss</span>

          <span class="c1"># Record loss</span>
          <span class="n">v_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l_v</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
          <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Loss_v</span><span class="o">=</span><span class="n">l_v</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

          <span class="c1"># Compute gradient and do SGD step</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="n">l_v</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Function to perform prediction</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      v: OthelloNet instance</span>
<span class="sd">        Data of the OthelloNet class instance above;</span>
<span class="sd">    """</span>
    <span class="c1"># Timing</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Preparing input</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">board</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">loss_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Calculates Mean squared error</span>

<span class="sd">    Args:</span>
<span class="sd">      targets: np.ndarray</span>
<span class="sd">        Ground Truth variables corresponding to input</span>
<span class="sd">      outputs: np.ndarray</span>
<span class="sd">        Predictions of Network</span>

<span class="sd">    Returns:</span>
<span class="sd">      MSE Loss calculated as: square of the difference between your model's predictions</span>
<span class="sd">      and the ground truth and average across the whole dataset</span>
<span class="sd">    """</span>
    <span class="c1"># Mean squared error (MSE)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">targets</span> <span class="o">-</span> <span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Code Checkpointing</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory does not exist! Making directory </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">folder</span><span class="p">))</span>
      <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory exists! "</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'state_dict'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),},</span> <span class="n">filepath</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved! "</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Load code checkpoint</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="c1"># https://github.com/pytorch/examples/blob/master/imagenet/main.py#L98</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
      <span class="k">raise</span> <span class="p">(</span><span class="s2">"No model in path </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>

    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">loadTrainExamples</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Helper function to load Training examples</span>

<span class="sd">  Args:</span>
<span class="sd">    folder: string</span>
<span class="sd">      Path specifying training examples</span>
<span class="sd">    filename: string</span>
<span class="sd">      File name of training examples</span>

<span class="sd">  Returns:</span>
<span class="sd">    trainExamplesHistory: list</span>
<span class="sd">      Returns examples based on the model were already collected (loaded)</span>
<span class="sd">  """</span>
  <span class="n">trainExamplesHistory</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">modelFile</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
  <span class="n">examplesFile</span> <span class="o">=</span> <span class="n">modelFile</span> <span class="o">+</span> <span class="s2">".examples"</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">examplesFile</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'File "</span><span class="si">{</span><span class="n">examplesFile</span><span class="si">}</span><span class="s1">" with trainExamples not found!'</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">"Continue? [y|n]"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">!=</span> <span class="s2">"y"</span><span class="p">:</span>
      <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"File with train examples found. Loading it..."</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">examplesFile</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
      <span class="n">trainExamplesHistory</span> <span class="o">=</span> <span class="n">Unpickler</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Loading done!'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">trainExamplesHistory</span>
</pre></div>
</div>
</div>
</div>
<p>The hyperparameters used throughout the notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">args</span> <span class="o">=</span> <span class="n">dotdict</span><span class="p">({</span>
    <span class="s1">'numIters'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>            <span class="c1"># In training, number of iterations = 1000 and num of episodes = 100</span>
    <span class="s1">'numEps'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>              <span class="c1"># Number of complete self-play games to simulate during a new iteration.</span>
    <span class="s1">'tempThreshold'</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>      <span class="c1"># To control exploration and exploitation</span>
    <span class="s1">'updateThreshold'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>   <span class="c1"># During arena playoff, new neural net will be accepted if threshold or more of games are won.</span>
    <span class="s1">'maxlenOfQueue'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>     <span class="c1"># Number of game examples to train the neural networks.</span>
    <span class="s1">'numMCTSSims'</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>        <span class="c1"># Number of games moves for MCTS to simulate.</span>
    <span class="s1">'arenaCompare'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>       <span class="c1"># Number of games to play during arena play to determine if new net will be accepted.</span>
    <span class="s1">'cpuct'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'maxDepth'</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span>             <span class="c1"># Maximum number of rollouts</span>
    <span class="s1">'numMCsims'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>           <span class="c1"># Number of monte carlo simulations</span>
    <span class="s1">'mc_topk'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>             <span class="c1"># Top k actions for monte carlo rollout</span>

    <span class="s1">'checkpoint'</span><span class="p">:</span> <span class="s1">'./temp/'</span><span class="p">,</span>
    <span class="s1">'load_model'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">'load_folder_file'</span><span class="p">:</span> <span class="p">(</span><span class="s1">'/dev/models/8x100x50'</span><span class="p">,</span><span class="s1">'best.pth.tar'</span><span class="p">),</span>
    <span class="s1">'numItersForTrainExamplesHistory'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>

    <span class="c1"># Define neural network arguments</span>
    <span class="s1">'lr'</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>               <span class="c1"># lr: Learning Rate</span>
    <span class="s1">'dropout'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'device'</span><span class="p">:</span> <span class="n">DEVICE</span><span class="p">,</span>
    <span class="s1">'num_channels'</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>Load in trained value network</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Load in trained value network</span>
<span class="n">model_save_name</span> <span class="o">=</span> <span class="s1">'ValueNetwork.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">vnet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
<span class="n">vnet</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">model_save_name</span><span class="p">)</span>

<span class="c1"># Alternative if the downloading of trained model didn't work (will train the model)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">'nma_rl_games/alpha-zero/pretrained_models/models/'</span><span class="p">):</span>

    <span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/data/"</span>
    <span class="n">loaded_games</span> <span class="o">=</span> <span class="n">loadTrainExamples</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint_1.pth.tar'</span><span class="p">)</span>

    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">vnet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
    <span class="n">vnet</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">loaded_games</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p>A reminder of the network architecture</p>
<figure>
<img src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W3D5_ReinforcementLearningForGames/static/CNN.jpg"/>
</figure></div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-train-a-policy-network-from-expert-game-data">
<h1>Section 1: Train a policy network from expert game data<a class="headerlink" href="#section-1-train-a-policy-network-from-expert-game-data" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~25mins</em></p>
<p><strong>Goal</strong>: How to train a policy network via supervised learning / behavioural cloning.</p>
<p><strong>Exercise</strong>:</p>
<ul class="simple">
<li><p>Train a network to predict the next move in an expert dataset by maximizing the log likelihood of the next action.</p></li>
</ul>
<div class="section" id="video-1-train-a-policy-network">
<h2>Video 1: Train a policy network<a class="headerlink" href="#video-1-train-a-policy-network" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "ac7c4b16956b4322998d8cf74b7fac3b"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-1-implement-policynetwork">
<h2>Coding Exercise 1: Implement <code class="docutils literal notranslate"><span class="pre">PolicyNetwork</span></code><a class="headerlink" href="#coding-exercise-1-implement-policynetwork" title="Permalink to this headline">¶</a></h2>
<p>In section 3 we simply chose to move based on the highest predicted value of the next step. Here, we will use a different approach. We will train a network to directly produce a policy function as a distribution over all possible discrete actions, given the current state. Learning will be based  on expert moves; thus, we call this behavioral cloning.</p>
<p>We will use the exact same network that we have used above for the value function learning. But now we will train the network explicitly on every single move of expert players.</p>
<p>For computing our objective function, we will use the negative log-likelihood of targets <span class="math notranslate nohighlight">\(t_i\)</span> by using the cross-entropy function:</p>
<div class="amsmath math notranslate nohighlight" id="equation-912b97a0-d43c-4a3a-bd00-01664c433104">
<span class="eqno">(131)<a class="headerlink" href="#equation-912b97a0-d43c-4a3a-bd00-01664c433104" title="Permalink to this equation">¶</a></span>\[\begin{equation}
L_{CE} = - \frac{1}{N} \sum_i^N t_i \cdot \log(output_i)
\end{equation}\]</div>
<p><strong>Note</strong>: remember that the OthelloNet already returns the <strong>Log</strong>-softmax of the output from the 3rd linear layer…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Initialise Policy Network</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Initalise policy network paramaters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">OthelloNNet</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getBoardSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">games</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Function for Policy Network Training</span>

<span class="sd">    Args:</span>
<span class="sd">      games: list</span>
<span class="sd">        List of examples where each example is of form (board, pi, v)</span>

<span class="sd">    Return:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">examples</span> <span class="ow">in</span> <span class="n">games</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'EPOCH ::: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">pi_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">batch_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="n">t</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch_count</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Training Policy Network'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
          <span class="n">sample_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">pis</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample_ids</span><span class="p">]))</span>
          <span class="n">boards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
          <span class="n">target_pis</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pis</span><span class="p">))</span>

          <span class="c1"># Predict</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">target_pis</span> <span class="o">=</span> <span class="n">boards</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target_pis</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

          <span class="c1">#################################################</span>
          <span class="c1">## TODO for students: ##</span>
          <span class="c1">## 1. Compute the policy (pi) predicted by OthelloNNet() ##</span>
          <span class="c1">## 2. Implement the loss_pi() function below and then use it to update the policy loss. ##</span>
          <span class="c1"># Fill out function and remove</span>
          <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Compute the output"</span><span class="p">)</span>
          <span class="c1">#################################################</span>
          <span class="c1"># Compute output</span>
          <span class="n">out_pi</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="o">...</span>
          <span class="n">l_pi</span> <span class="o">=</span> <span class="o">...</span>

          <span class="c1"># Record loss</span>
          <span class="n">pi_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l_pi</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
          <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Loss_pi</span><span class="o">=</span><span class="n">l_pi</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

          <span class="c1"># Compute gradient and do SGD step</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="n">l_pi</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Function to perform prediction</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      Data from the OthelloNet class instance above;</span>
<span class="sd">    """</span>
    <span class="c1"># Timing</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Preparing input</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">board</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">pi</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">loss_pi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Calculates Negative Log Likelihood(NLL) of Targets</span>

<span class="sd">    Args:</span>
<span class="sd">      targets: np.ndarray</span>
<span class="sd">        Ground Truth variables corresponding to input</span>
<span class="sd">      outputs: np.ndarray</span>
<span class="sd">        Predictions of Network</span>

<span class="sd">    Returns:</span>
<span class="sd">      Negative Log Likelihood calculated as: When training a model, we aspire to find the minima of a</span>
<span class="sd">      loss function given a set of parameters (in a neural network, these are the weights and biases).</span>
<span class="sd">      Sum the loss function to all the correct classes. So, whenever the network assigns high confidence at</span>
<span class="sd">      the correct class, the NLL is low, but when the network assigns low confidence at the correct class,</span>
<span class="sd">      the NLL is high.</span>
<span class="sd">    """</span>
    <span class="c1">#################################################</span>
    <span class="c1">## TODO for students: To implement the loss function, please compute and return the negative log likelihood of targets.</span>
    <span class="c1">## For more information, here is a reference that connects the expression to the neg-log-prob: https://gombru.github.io/2018/05/23/cross_entropy_loss/</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Compute the loss"</span><span class="p">)</span>
    <span class="c1">#################################################</span>
    <span class="k">return</span> <span class="o">...</span>

  <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Code Checkpointing</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory does not exist! Making directory </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">folder</span><span class="p">))</span>
      <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory exists! "</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'state_dict'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),},</span> <span class="n">filepath</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved! "</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Load code checkpoint</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="c1"># https://github.com/pytorch/examples/blob/master/imagenet/main.py#L98</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
      <span class="k">raise</span> <span class="p">(</span><span class="s2">"No model in path </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">])</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 1: Implement PolicyNetwork'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial3_Solution_7c7e4c5e.py"><em>Click for solution</em></a></p>
<div class="section" id="train-the-policy-network">
<h3>Train the policy network<a class="headerlink" href="#train-the-policy-network" title="Permalink to this headline">¶</a></h3>
<p><strong>Important:</strong> Only run this cell if you do not have access to the pretrained models in the <code class="docutils literal notranslate"><span class="pre">rl_for_games</span></code> repository.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">'nma_rl_games/alpha-zero/pretrained_models/models/'</span><span class="p">):</span>
  <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
  <span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
  <span class="n">pnet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
  <span class="n">pnet</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">loaded_games</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-use-a-trained-policy-network-to-play-games">
<h1>Section 2: Use a trained policy network to play games<a class="headerlink" href="#section-2-use-a-trained-policy-network-to-play-games" title="Permalink to this headline">¶</a></h1>
<p>Time estimate: ~25mins</p>
<p><strong>Goal</strong>: Use a policy network to play games.</p>
<p><strong>Exercise:</strong></p>
<ul class="simple">
<li><p>Use the policy network to give probabilities for the next move.</p></li>
<li><p>Build a player that takes the move given the maximum probability by the network.</p></li>
<li><p>Compare this to another player that samples moves according to the probability distribution output by the network.</p></li>
</ul>
<div class="section" id="video-2-play-games-using-a-policy-network">
<h2>Video 2: Play games using a policy network<a class="headerlink" href="#video-2-play-games-using-a-policy-network" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d53c08e2c7934cfbb6a534f44603f1bc"}
</script></div>
</div>
<p><strong>Note</strong>: in the video’s softmax function, <span class="math notranslate nohighlight">\(T=1\)</span> is the softmax kernel and <span class="math notranslate nohighlight">\(z_i\)</span> is the networks output before softmax transformation.</p>
</div>
<div class="section" id="coding-exercise-2-implement-the-policybasedplayer">
<h2>Coding Exercise 2: Implement the <code class="docutils literal notranslate"><span class="pre">PolicyBasedPlayer</span></code><a class="headerlink" href="#coding-exercise-2-implement-the-policybasedplayer" title="Permalink to this headline">¶</a></h2>
<p>First we initialize the game and load in the pre-trained policy net.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_save_name</span> <span class="o">=</span> <span class="s1">'PolicyNetwork.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">pnet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
<span class="n">pnet</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">model_save_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p>Next we create our policy-based player by using the policy network to produce a set of action probabilities for all valid board positions.</p>
<p>There are at least 2 ways then to choose the next action:</p>
<ol class="simple">
<li><p>sampling-based player: we sample from the action probability distribution. This will result in actions with higher probabilities to be randomly selected more often than actions with lower probabilities.</p></li>
<li><p>“greedy” player: we always choose the action with the highest action probability.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PolicyBasedPlayer</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Simulate Policy Based Player</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">,</span> <span class="n">greedy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Initialize Policy based player parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      pnet: Policy Network instance</span>
<span class="sd">        Instance of the Policy Network class above</span>
<span class="sd">      greedy: Boolean</span>
<span class="sd">        If true, implement greedy approach</span>
<span class="sd">        Else, implement random sample policy based player</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pnet</span> <span class="o">=</span> <span class="n">pnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">greedy</span> <span class="o">=</span> <span class="n">greedy</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Simulate game play</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      a: np.ndarray</span>
<span class="sd">        If greedy, implement greedy policy player</span>
<span class="sd">        Else, implement random sample policy based player</span>
<span class="sd">    """</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1">#################################################</span>
    <span class="c1">## TODO for students:  ##</span>
    <span class="c1">## 1. Compute the action probabilities using policy network pnet()</span>
    <span class="c1">## 2. Mask invalid moves (set their action probability to 0) using valids variable and the action probabilites computed above.</span>
    <span class="c1">## 3. Compute the sum over the probabilities of the valid actions and store them in sum_vap.</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define the play"</span><span class="p">)</span>
    <span class="c1">#################################################</span>
    <span class="n">action_probs</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">vap</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># Masking invalid moves</span>
    <span class="n">sum_vap</span> <span class="o">=</span> <span class="o">...</span>

    <span class="k">if</span> <span class="n">sum_vap</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">vap</span> <span class="o">/=</span> <span class="n">sum_vap</span>  <span class="c1"># Renormalize</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If all valid moves were masked we make all valid moves equally probable</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"All valid moves were masked, doing a workaround."</span><span class="p">)</span>
      <span class="n">vap</span> <span class="o">=</span> <span class="n">vap</span> <span class="o">+</span> <span class="n">valids</span>
      <span class="n">vap</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vap</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy</span><span class="p">:</span>
      <span class="c1"># Greedy policy player</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">vap</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vap</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Sample-based policy player</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="n">vap</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 5: Implement the PolicyBasedPlayer'</span><span class="p">)</span>

<span class="c1"># Playing games</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">num_games</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">player1</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">,</span> <span class="n">greedy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">player2</span> <span class="o">=</span> <span class="n">RandomPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">player1</span><span class="p">,</span> <span class="n">player2</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="c1">## Uncomment below to test!</span>
<span class="c1"># result = arena.playGames(num_games, verbose=False)</span>
<span class="c1"># print(f"\n\n{result}")</span>
<span class="c1"># win_rate_player1 = result[0] / num_games</span>
<span class="c1"># print(f"\nWin rate for greedy policy player 1 (vs random player 2) over {num_games} games: {round(win_rate_player1*100, 1)}%")</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial3_Solution_738279ec.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">greedy</span> <span class="n">policy</span> <span class="n">player</span> <span class="mi">1</span> <span class="p">(</span><span class="n">vs</span> <span class="n">random</span> <span class="n">player</span> <span class="mi">2</span><span class="p">)</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">80.0</span><span class="o">%</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_save_name</span> <span class="o">=</span> <span class="s1">'PolicyNetwork.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">pnet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
<span class="n">pnet</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">model_save_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-player-comparisons">
<h1>Section 3: Player comparisons<a class="headerlink" href="#section-3-player-comparisons" title="Permalink to this headline">¶</a></h1>
<p>Time estimate: ~10mins</p>
<p>Next we want to compare how our different players fair, i.e. random vs. value-based vs. policy-based (greedy or sampling-based)… Feel free to explore some of the comparisons we have not explicitly provided below.</p>
<div class="section" id="comparing-a-sampling-based-policy-based-player-versus-a-random-player">
<h2>Comparing a sampling-based policy based player versus a random player<a class="headerlink" href="#comparing-a-sampling-based-policy-based-player-versus-a-random-player" title="Permalink to this headline">¶</a></h2>
<p>There’s often randomness in the results as we are running the players for a low number of games (only 20 games due to compute + time costs). So, when students are running the cells they might not get the expected result. To better measure the strength of players you can run more games!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">num_games</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">player1</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">,</span> <span class="n">greedy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">player2</span> <span class="o">=</span> <span class="n">RandomPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">player1</span><span class="p">,</span> <span class="n">player2</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Win rate for sample-based policy based player 1 (vs random player 2) over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">sample</span><span class="o">-</span><span class="n">based</span> <span class="n">policy</span> <span class="n">based</span> <span class="n">player</span> <span class="mi">1</span> <span class="p">(</span><span class="n">vs</span> <span class="n">random</span> <span class="n">player</span> <span class="mi">2</span><span class="p">)</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">95.0</span><span class="o">%</span>
</pre></div>
</div>
</div>
<div class="section" id="compare-greedy-policy-based-player-versus-value-based-player">
<h2>Compare greedy policy based player versus value based player<a class="headerlink" href="#compare-greedy-policy-based-player-versus-value-based-player" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">num_games</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">player1</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">player2</span> <span class="o">=</span> <span class="n">ValueBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">vnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">player1</span><span class="p">,</span> <span class="n">player2</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Win rate for greedy policy based player 1 vs value based player) over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
<div class="section" id="compare-greedy-policy-based-player-versus-sampling-based-policy-player">
<h2>Compare greedy policy based player versus sampling-based policy player<a class="headerlink" href="#compare-greedy-policy-based-player-versus-sampling-based-policy-player" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">num_games</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">player1</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span> <span class="c1"># greedy player</span>
<span class="n">player2</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">,</span> <span class="n">greedy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">play</span> <span class="c1"># sample-based player</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">player1</span><span class="p">,</span> <span class="n">player2</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Win rate for greedy policy player 1 (vs sample based policy player) over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<p>We’ve been diving into the code so take a few minutes to recap what the different players are with your group and how they’re choosing their actions (random player, value player, greedy policy player, sample-based policy player).</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-ethical-aspects">
<h1>Section 4: Ethical aspects<a class="headerlink" href="#section-4-ethical-aspects" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~5mins</em></p>
<div class="section" id="video-3-unstoppable-opponents">
<h2>Video 3: Unstoppable opponents<a class="headerlink" href="#video-3-unstoppable-opponents" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "97475009bc674c4d8481cd9bb5462f44"}
</script></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, you have learned about policy-based players and compared them to random and value-based players.</p>
<div class="section" id="airtable-submission-link">
<h2>Airtable Submission Link<a class="headerlink" href="#airtable-submission-link" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Airtable Submission Link</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPydisplay</span>
<span class="n">IPydisplay</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span>
   <span class="sa">f</span><span class="s2">"""</span>
<span class="s2"> &lt;div&gt;</span>
<span class="s2">   &lt;a href= "</span><span class="si">{</span><span class="n">atform</span><span class="o">.</span><span class="n">url</span><span class="p">()</span><span class="si">}</span><span class="s2">" target="_blank"&gt;</span>
<span class="s2">   &lt;img src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1"</span>
<span class="s2"> alt="button link to Airtable" style="width:410px"&gt;&lt;/a&gt;</span>
<span class="s2">   &lt;/div&gt;"""</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
<a href="https://portal.neuromatchacademy.org/api/redirect/to/95651a47-083f-406e-a6cd-8af24670c5bc?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzNENV9UMyIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTY1OTAxMTExOS42Njc3NjQyfSwgeyJldmVudCI6ICJWaWRlbyAxOiBUcmFpbiBhIHBvbGljeSBuZXR3b3JrIiwgInRzIjogMTY1OTAxMTEzMy43MDY3MDE4fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgMTogSW1wbGVtZW50IFBvbGljeU5ldHdvcmsiLCAidHMiOiAxNjU5MDExMTMzLjc2NjA5MzV9LCB7ImV2ZW50IjogIlZpZGVvIDI6IFBsYXkgZ2FtZXMgdXNpbmcgYSBwb2xpY3kgbmV0d29yayIsICJ0cyI6IDE2NTkwMTExMzMuODQwOTU3Nn0sIHsiZXZlbnQiOiAiQ29kaW5nIEV4ZXJjaXNlIDU6IEltcGxlbWVudCB0aGUgUG9saWN5QmFzZWRQbGF5ZXIiLCAidHMiOiAxNjU5MDExMTMzLjk1OTY5NzV9LCB7ImV2ZW50IjogIlZpZGVvIDM6IFVuc3RvcHBhYmxlIG9wcG9uZW50cyIsICJ0cyI6IDE2NTkwMTExMzQuMzQ2NzIxNn0sIHsiZXZlbnQiOiAidXJsIGdlbmVyYXRlZCIsICJ0cyI6IDE2NTkwMTExMzQuMzY4NzEwOH1dfQ%3D%3D" target="_blank">
<img alt="button link to Airtable" src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1" style="width:410px"/></a>
</div></div></div>
</div>
</div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {"c746a5f24c9e4f1cbc4f0019a708dd0b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6e2cd667c1064f78947389a6fbf7b69e": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c746a5f24c9e4f1cbc4f0019a708dd0b", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1hQ4y127GJ\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f0aa93b2e50>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1hQ4y127GJ&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "340134936c8447f09c0a1ee89e790fd0": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a92c8db34af841c5b767a7d7885cef0a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_340134936c8447f09c0a1ee89e790fd0", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=vj9gKNJ19D8\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f0aa93b2d90>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/vj9gKNJ19D8?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "6cac464e4dd84eec8d33dc188c86f74d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ac7c4b16956b4322998d8cf74b7fac3b": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_a92c8db34af841c5b767a7d7885cef0a", "IPY_MODEL_6e2cd667c1064f78947389a6fbf7b69e"], "layout": "IPY_MODEL_6cac464e4dd84eec8d33dc188c86f74d", "selected_index": 0}}, "c7365dd3fe7d403291b459eac1bee3e2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "04e7f4b4c7db4e009eacdcd4c8a142fd": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c7365dd3fe7d403291b459eac1bee3e2", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1aq4y1S7o4\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f0aa9522990>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1aq4y1S7o4&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "2f5dfb707a0e441bba81312eb2b49561": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "94e37d7f7d55495d9d8d3f57308840bd": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_2f5dfb707a0e441bba81312eb2b49561", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=yHtVqT2Nstk\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f0aa9522550>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/yHtVqT2Nstk?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "0fd5254838d84b3cbd68de6d22e08020": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d53c08e2c7934cfbb6a534f44603f1bc": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_94e37d7f7d55495d9d8d3f57308840bd", "IPY_MODEL_04e7f4b4c7db4e009eacdcd4c8a142fd"], "layout": "IPY_MODEL_0fd5254838d84b3cbd68de6d22e08020", "selected_index": 0}}, "889b27cca83d430ea71335d9fd3bf4de": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a77106e5cdbc43f6850d9d0de492e1e7": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_889b27cca83d430ea71335d9fd3bf4de", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1WA411w7mw\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f0aa949d810>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1WA411w7mw&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "fca196f7ed9446969313305493efd3fe": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0fdbaf6ddb6d4c398cc451e2d3dfec94": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_fca196f7ed9446969313305493efd3fe", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=q7181lvoNpM\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f0aa94e6450>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/q7181lvoNpM?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "8e9138e8885b4b71b9977a1d96b8f07b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "97475009bc674c4d8481cd9bb5462f44": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_0fdbaf6ddb6d4c398cc451e2d3dfec94", "IPY_MODEL_a77106e5cdbc43f6850d9d0de492e1e7"], "layout": "IPY_MODEL_8e9138e8885b4b71b9977a1d96b8f07b", "selected_index": 0}}}, "version_major": 2, "version_minor": 0}
</script>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D5_ReinforcementLearningForGames/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W3D5_Tutorial2.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 2: Value-Based Player</p>
</div>
</a>
<a class="right-next" href="W3D5_Tutorial4.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Bonus Tutorial: Planning with Monte Carlo</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br/>
  
      © Copyright 2021.<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>